# -*- coding: utf-8 -*-
"""
/***************************************************************************
 FireToolbox
                                 A QGIS plugin
 A collection of fire insights related algorithms
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                              -------------------
        begin                : 2023-08-30
        copyright            : (C) 2023 by Fernando Badilla Veliz - Fire2a.com
        email                : fbadilla@ing.uchile.cl
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
TODO:
    group results https://gis.stackexchange.com/questions/416542/adding-output-layers-of-qgis-processing-scripts-to-group-using-pyqgis
util:
    https://gis.stackexchange.com/questions/314036/programmatically-styling-layer-after-output-is-returned-from-qgis-3-processing-s
    https://lists.osgeo.org/pipermail/qgis-developer/2021-June/063741.html
    https://gis.stackexchange.com/questions/375987/customizing-qgsprocessing-output-layer-name
    https://gis.stackexchange.com/questions/448603/change-the-symbology-of-a-vector-output-layer-that-is-returned-from-a-processing
    https://gis.stackexchange.com/questions/414559/qgis-iterative-rasterize-naming
    https://gis.stackexchange.com/questions/306659/pyqgis-style-layer-after-processing-with-qml-file

"""

__author__ = "Fernando Badilla Veliz - Fire2a.com"
__date__ = "2023-08-30"
__copyright__ = "(C) 2023 by Fernando Badilla Veliz - Fire2a.com"

# This will get replaced with a git SHA1 when you do a git archive

__revision__ = "$Format:%H$"

from functools import partial
from multiprocessing import Pool, cpu_count
from os import sep
from pathlib import Path
from pickle import dump as pickle_dump
from pickle import load as pickle_load
from platform import system as platform_system
from re import findall, search
from typing import Any, Tuple

import processing
from fire2a.raster import id2xy, read_raster, transform_coords_to_georef
from fire2a.utils import loadtxt_nodata
from networkx import DiGraph, MultiDiGraph, betweenness_centrality, single_source_dijkstra_path
# from matplotlib import colormaps
# from matplotlib.colors import to_rgba_array
from numpy import any as np_any
from numpy import (argsort, array, dtype, float32, fromiter, int16, int32, loadtxt, ndarray, sqrt, unique, vectorize,
                   vstack, zeros)
from osgeo import gdal, ogr, osr
from osgeo.gdal import GDT_Float32, GDT_Int16
from qgis.core import (Qgis, QgsColorRampShader, QgsFeature, QgsFeatureSink, QgsField, QgsFields, QgsGeometry,
                       QgsGraduatedSymbolRenderer, QgsLineString, QgsMessageLog, QgsPalettedRasterRenderer, QgsPoint,
                       QgsProcessing, QgsProcessingAlgorithm, QgsProcessingContext, QgsProcessingException,
                       QgsProcessingLayerPostProcessorInterface, QgsProcessingParameterBoolean,
                       QgsProcessingParameterDefinition, QgsProcessingParameterEnum, QgsProcessingParameterFeatureSink,
                       QgsProcessingParameterFile, QgsProcessingParameterFileDestination,
                       QgsProcessingParameterFolderDestination, QgsProcessingParameterNumber,
                       QgsProcessingParameterRasterDestination, QgsProcessingParameterRasterLayer, QgsProcessingUtils,
                       QgsProject, QgsRasterBandStats, QgsRasterFileWriter, QgsRasterShader,
                       QgsSingleBandPseudoColorRenderer, QgsWkbTypes)
from qgis.PyQt.QtCore import QCoreApplication, QVariant
from qgis.PyQt.QtGui import QColor, QIcon
from scipy import stats as scipy_stats

from .algorithm_utils import get_output_raster_format, write_log
from .config import NAME, SIM_OUTPUTS, STATS, TAG, jolo

plugin_dir = Path(__file__).parent
assets_dir = Path(plugin_dir, "simulator")
gdal.UseExceptions()


class IgnitionPointsSIMPP(QgsProcessingAlgorithm):
    """Ignition Points Simulation Post Processing Algorithm load LogFile.txt and create a point layer"""

    BASE_LAYER = "BaseLayer"
    IN_LOG = "LogFile"
    OUT_LAYER = "IgnitionPointsLayer"

    def checkParameterValues(self, parameters: dict[str, Any], context: QgsProcessingContext) -> tuple[bool, str]:
        """log file exists and is not empty"""
        log_file = Path(self.parameterAsString(parameters, self.IN_LOG, context))
        if not log_file.stat().st_size > 0:
            return False, f"{log_file} file is empty!"
        log_text = log_file.read_text(encoding="utf-8")
        simulation_id, ignition_cell = fromiter(
            findall("ignition point for Year [0-9]*, sim ([0-9]+): ([0-9]+)", log_text), dtype=dtype((int32, 2))
        ).T
        if len(simulation_id) == 0 or len(ignition_cell) == 0:
            return (
                False,
                (
                    f"{log_file} file does not contain any match for ignition points: 'ignition point for Year [0-9]*,"
                    " sim ([0-9]+): ([0-9]+)'"
                ),
            )
        return True, ""

    def initAlgorithm(self, config):
        self.addParameter(
            QgsProcessingParameterRasterLayer(
                name=self.BASE_LAYER,
                description=self.tr("Base raster (normally fuel or elevation) to get the geotransform"),
                defaultValue=[QgsProcessing.TypeRaster],
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterFile(
                name=self.IN_LOG,
                description="Simulator log file (normally firesim_yymmdd_HHMMSS/results/LogFile.txt)",
                behavior=QgsProcessingParameterFile.File,
                extension="txt",
                defaultValue=None,
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterFeatureSink(
                name=self.OUT_LAYER,
                description=self.tr("Output ignition point(s) layer"),
                type=QgsProcessing.TypeVectorPoint,
            )
        )

    def processAlgorithm(self, parameters, context, feedback):
        """Here is where the processing itself takes place."""
        # BASE LAYER
        base_raster = self.parameterAsRasterLayer(parameters, self.BASE_LAYER, context)
        _, raster_props = read_raster(base_raster.publicSource(), data=False)
        feedback.pushDebugInfo(f"base_raster.crs.authid: {base_raster.crs().authid()}\n")
        # log file
        log_text = Path(self.parameterAsString(parameters, self.IN_LOG, context)).read_text(encoding="utf-8")
        preview_from, preview_to = 34, 256 * 2 - 34
        if len(log_text) < preview_from:
            preview_from = 0
        if len(log_text) < preview_to:
            preview_to = len(log_text)
        feedback.pushDebugInfo(f"preview of simulation log:\n{log_text[preview_from: preview_to]}\n")
        # create layer
        fields = QgsFields()
        fields.append(QgsField(name="simulation", type=QVariant.Int, len=10))
        fields.append(QgsField(name="cell", type=QVariant.Int, len=10))
        fields.append(QgsField(name="x_pixel", type=QVariant.Int, len=10))
        fields.append(QgsField(name="y_line", type=QVariant.Int, len=10))
        (sink, dest_id) = self.parameterAsSink(
            parameters,
            self.OUT_LAYER,
            context,
            fields,
            QgsWkbTypes.Point,  # >v3.3 ? Qgis.WkbType.Point
            base_raster.crs(),
        )
        # feedback.pushDebugInfo(f"dest_id: {dest_id}, type: {type(dest_id)}")
        # feedback.pushDebugInfo(f"sink: {sink}, type: {type(sink)}, dir: {dir(sink)}")
        feedback.pushDebugInfo(f"output layer id: {dest_id}\n")
        # parse log file
        simulation_id, ignition_cell = fromiter(
            findall("ignition point for Year [0-9]*, sim ([0-9]+): ([0-9]+)", log_text), dtype=dtype((int32, 2))
        ).T
        ignition_cell -= 1  # 1 based to 0 based
        # add features
        features = []
        for sim_id, cell in zip(simulation_id, ignition_cell):
            i, j = id2xy(cell, raster_props["RasterXSize"], raster_props["RasterYSize"])
            x, y = transform_coords_to_georef(i + 0.5, j + 0.5, raster_props["Transform"])
            feature = QgsFeature(fields)
            feature.setId(int(sim_id))
            feature.setAttributes([int(sim_id), int(cell + 1), int(i), int(j)])
            feature.setGeometry(QgsGeometry(QgsPoint(x, y)))
            sink.addFeature(feature, QgsFeatureSink.FastInsert)
            feedback.pushDebugInfo(f"simulation id: {sim_id}, ignition cell: {cell}, x: {x}, y: {y}, i: {i}, j: {j}")
            if feedback.isCanceled():
                break
        # feedback.pushDebugInfo(f"addFeatures: {sink}, {type(sink)}")
        feedback.pushDebugInfo("\n")
        processing.run(
            "qgis:setstyleforvectorlayer",
            {"INPUT": dest_id, "STYLE": str(Path(assets_dir, "ignition_points.qml"))},
            context=context,
            feedback=feedback,
            is_child_algorithm=True,
        )
        if context.willLoadLayerOnCompletion(dest_id):
            layer = QgsProcessingUtils.mapLayerFromString(dest_id, context)
            layer_details = context.LayerDetails(
                "Ignition Points",
                context.project(),
                dest_id,
                QgsProcessingUtils.LayerHint.Vector,
                # layer.name(), context.project(), dest_id, QgsProcessingUtils.LayerHint.Vector
            )
            layer_details.groupName = NAME["layer_group"]
            layer_details.layerSortKey = 0
            context.addLayerToLoadOnCompletion(dest_id, layer_details)

        write_log(feedback, name=self.name())
        return {self.OUT_LAYER: dest_id}

    def tr(self, string):
        return QCoreApplication.translate("Processing", string)

    def createInstance(self):
        return IgnitionPointsSIMPP()

    def group(self):
        return self.tr("Simulator Post Processing")

    def groupId(self):
        return "simulatorpostprocessing"

    def name(self):
        return "ignitionpoints"

    def displayName(self):
        return self.tr("Ignition Points")

    def icon(self):
        return QIcon(":/plugins/fireanalyticstoolbox/assets/ignitionpoint.svg")


class PostSimulationAlgorithm(QgsProcessingAlgorithm):
    """Cell2Fire results post processing bundle"""

    BASE_LAYER = "BaseLayer"
    OUTPUT_DIR = "OutputDirectory"
    RESULTS_DIR = "ResultsDirectory"
    MSGS = "EnablePropagationDiGraph"

    def initAlgorithm(self, config):
        """inputs and output of the algorithm"""
        self.addParameter(
            QgsProcessingParameterRasterLayer(
                name=self.BASE_LAYER,
                description=self.tr("Base raster (normally fuel or elevation) to get the geotransform"),
                defaultValue=[QgsProcessing.TypeRaster],
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterBoolean(
                name=self.MSGS,
                description=("Enable propagation directed graph"),
                defaultValue=False,
                optional=True,
            )
        )
        project_path = QgsProject().instance().absolutePath()
        project_path = project_path if project_path != "" else None
        self.addParameter(
            QgsProcessingParameterFile(
                name=self.RESULTS_DIR,
                description="Simulation Results directory (normally firesim_yymmdd_HHMMSS/results)",
                behavior=QgsProcessingParameterFile.Folder,
                defaultValue=project_path,
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterFolderDestination(
                name=self.OUTPUT_DIR,
                description="Output directory",
                defaultValue=None,
                optional=True,
                createByDefault=True,
            )
        )

    def checkParameterValues(self, parameters: dict[str, Any], context: QgsProcessingContext) -> tuple[bool, str]:
        results_directory = Path(self.parameterAsString(parameters, self.RESULTS_DIR, context))
        if not results_directory.is_dir():
            return False, f"provided results is not a directory: {results_directory}"
        if next(results_directory.iterdir(), None) is None:
            return False, f"provided results is empty: {results_directory}"
        return True, ""

    def processAlgorithm(self, parameters, context, feedback):
        """Here is where the processing itself takes place."""
        # feedback.pushDebugInfo("processAlgorithm start")
        # feedback.pushDebugInfo(f"context args: {context.asQgisProcessArguments()}")
        # feedback.pushDebugInfo(f"parameters {parameters}")
        output_dict = {}
        # OUTPUT DIR
        output_dir = Path(self.parameterAsString(parameters, self.OUTPUT_DIR, context))
        out_is = output_dir.is_dir()
        feedback.pushDebugInfo(f"output_dir: {output_dir}, {output_dir.is_dir()}")
        output_dict[self.OUTPUT_DIR] = output_dir
        # BASE LAYER
        base_raster = self.parameterAsRasterLayer(parameters, self.BASE_LAYER, context)
        sp_ref = osr.SpatialReference()
        sp_ref.SetFromUserInput(base_raster.crs().authid())
        # RESULTS DIR
        results_dir = Path(self.parameterAsString(parameters, self.RESULTS_DIR, context))

        # IgnitionPoints
        log_file = Path(results_dir, "LogFile.txt")
        if log_file.is_file() and log_file.stat().st_size > 0:
            feedback.pushDebugInfo(log_file.read_text())
            if out_is:
                out = (output_dir / "IgnitionPointsLayer").touch()
            else:
                out = QgsProcessing.TEMPORARY_OUTPUT
            igpt_out = processing.run(
                "fire2a:ignitionpoints",
                {
                    "BaseLayer": base_raster,
                    "IgnitionPointsLayer": out,
                    "LogFile": str(results_dir / "LogFile.txt"),
                },
                context=context,
                feedback=feedback,
                is_child_algorithm=True,
            )
            layer_details = QgsProcessingContext.LayerDetails(
                "Ignition Points",
                context.project(),
                "Ignition Points",
                QgsProcessingUtils.LayerHint.Vector,
            )
            layer_details.groupName = NAME["layer_group"]
            layer_details.layerSortKey = 0
            context.addLayerToLoadOnCompletion(
                igpt_out["IgnitionPointsLayer"],
                layer_details,
            )
            output_dict["IgnitionPoints"] = igpt_out["IgnitionPointsLayer"]
        else:
            feedback.reportError(f"{log_file} not found or empty!")
            raise QgsProcessingException(f"{log_file} not found or empty!")

        # stats
        for stat in STATS:
            if sample_file := next(Path(results_dir).glob(stat["dir"] + sep + stat["file"] + "*" + stat["ext"]), None):
                stat_out = processing.run(
                    "fire2a:statistic",
                    {
                        "BaseLayer": base_raster,
                        "SampleStatisticFile": str(sample_file),
                        "DataType": stat["dtype"],
                        "OutputRaster": QgsProcessing.TEMPORARY_OUTPUT,
                        "OutputRasterStats": QgsProcessing.TEMPORARY_OUTPUT,
                    },
                    context=context,
                    feedback=feedback,
                    is_child_algorithm=True,
                )
                # ui load
                # each sim in a band
                layer_details = context.LayerDetails(
                    stat["name"],
                    context.project(),
                    stat["name"],
                    QgsProcessingUtils.LayerHint.Raster,
                )
                layer_details.groupName = NAME["layer_group"]
                layer_details.layerSortKey = 5
                context.addLayerToLoadOnCompletion(stat_out["OutputRaster"], layer_details)
                if stat["dtype"] == "float32":
                    context.layerToLoadOnCompletionDetails(stat_out["OutputRaster"]).setPostProcessor(
                        run_alg_styler(
                            stat["name"],
                        )
                    )
                else:
                    context.layerToLoadOnCompletionDetails(stat_out["OutputRaster"]).setPostProcessor(
                        run_alg_styler_bin(
                            stat["name"],
                        )
                    )
                output_dict[stat["name"]] = stat_out["OutputRaster"]
                # mean & stddev
                layer_details = context.LayerDetails(
                    "Mean&StdDev " + stat["name"],
                    context.project(),
                    "Mean&StdDev " + stat["name"],
                    QgsProcessingUtils.LayerHint.Raster,
                )
                layer_details.groupName = NAME["layer_group"]
                layer_details.layerSortKey = 4
                context.addLayerToLoadOnCompletion(stat_out["OutputRasterStats"], layer_details)
                context.layerToLoadOnCompletionDetails(stat_out["OutputRasterStats"]).setPostProcessor(
                    run_alg_styler(
                        "Mean&StdDev " + stat["name"],
                    )
                )
                output_dict[stat["name"] + "Stats"] = stat_out["OutputRasterStats"]

        # grids
        grids = [item for item in SIM_OUTPUTS if item["name"] == "Propagation Fire Scars"][0]
        if sample_file:= next(Path(results_dir).glob(grids["dir"] + "*" + sep + grids["file"] + "*" + grids["ext"]), None):  # fmt: skip
            scar_out = processing.run(
                "fire2a:scar",
                {
                    "BaseLayer": base_raster,
                    "SampleScarFile": str(sample_file),
                    "ScarRaster": QgsProcessing.TEMPORARY_OUTPUT,
                    "ScarPolygon": QgsProcessing.TEMPORARY_OUTPUT,
                    "BurnProbability": QgsProcessing.TEMPORARY_OUTPUT,
                },
                context=context,
                feedback=feedback,
                is_child_algorithm=True,
            )
            # final scars raster
            if scar_raster := scar_out.get("ScarRaster"):
                # layer_details = context.layerToLoadOnCompletionDetails(scar_raster)
                layer_details = context.LayerDetails(
                    "Final Scars",
                    context.project(),
                    "Final Scars",
                    QgsProcessingUtils.LayerHint.Raster,
                )
                layer_details.setPostProcessor(run_alg_styler_bin("Final Scars"))
                layer_details.forceName = True
                layer_details.groupName = NAME["layer_group"]
                layer_details.layerSortKey = 1
                context.addLayerToLoadOnCompletion(scar_raster, layer_details)
                output_dict["ScarRaster"] = scar_raster
            # burnprob
            if bplayer := scar_out.get("BurnProbability"):
                # layer_details = context.layerToLoadOnCompletionDetails(bplayer)
                layer_details = context.LayerDetails(
                    "BurnProbability",
                    context.project(),
                    "BurnProbability",
                    QgsProcessingUtils.LayerHint.Raster,
                )
                layer_details.setPostProcessor(run_alg_styler("Burn Probability"))
                layer_details.forceName = True
                layer_details.groupName = NAME["layer_group"]
                layer_details.layerSortKey = 3
                context.addLayerToLoadOnCompletion(bplayer, layer_details)
                output_dict["BurnProbability"] = bplayer
            # grids polygons
            if scar_poly := scar_out.get("ScarPolygon"):
                # feedback.pushDebugInfo(f"{scar_poly=}")
                layer_details = context.LayerDetails(
                    "Propagation Scars",
                    context.project(),
                    "Propagation Scars",
                    QgsProcessingUtils.LayerHint.Vector,
                )
                layer_details.forceName = True
                layer_details.groupName = NAME["layer_group"]
                layer_details.layerSortKey = 3
                context.addLayerToLoadOnCompletion(scar_poly, layer_details)
                output_dict["ScarPolygon"] = scar_poly
                """
                if scar_fixed_geom := processing.run(
                    "native:fixgeometries",
                    {"INPUT": scar_poly, "METHOD": 1, "OUTPUT": QgsProcessing.TEMPORARY_OUTPUT},
                    context=context,
                    feedback=feedback,
                    is_child_algorithm=True,
                ):
                    # feedback.pushDebugInfo(f"{scar_fixed_geom=}")
                    if scar_fixed_geom := scar_fixed_geom.get("OUTPUT"):
                        layer_details = context.LayerDetails(
                            "Propagation Scars",
                            context.project(),
                            "Propagation Scars",
                            QgsProcessingUtils.LayerHint.Vector,
                        )
                        layer_details.forceName = True
                        layer_details.groupName = NAME["layer_group"]
                        layer_details.layerSortKey = 3
                        context.addLayerToLoadOnCompletion(scar_fixed_geom, layer_details)
                        output_dict["ScarPolygon"] = scar_fixed_geom
                """

        # messages
        if self.parameterAsBool(parameters, self.MSGS, context):
            msgs = [item for item in SIM_OUTPUTS if item["name"] == "Propagation Directed Graph"][0]
            if sample_file := next(Path(results_dir, msgs["dir"]).glob(msgs["file"] + "*" + msgs["ext"]), None):
                msg_out = processing.run(
                    "fire2a:propagationdigraph",
                    {
                        "BaseLayer": base_raster,
                        "SampleMessagesFile": str(sample_file),
                        "PropagationDirectedGraph": QgsProcessing.TEMPORARY_OUTPUT,
                    },
                    context=context,
                    feedback=feedback,
                    is_child_algorithm=True,
                )
                layer_details = QgsProcessingContext.LayerDetails(
                    "PropagationDirectedGraph",
                    context.project(),
                    "PropagationDirectedGraph",
                    QgsProcessingUtils.LayerHint.Vector,
                )
                layer_details.groupName = NAME["layer_group"]
                layer_details.layerSortKey = 1
                context.addLayerToLoadOnCompletion(
                    msg_out["PropagationDirectedGraph"],
                    layer_details,
                )
                context.layerToLoadOnCompletionDetails(msg_out["PropagationDirectedGraph"]).setPostProcessor(
                    run_alg_styler_propagation()
                )
                output_dict["PropagationDirectedGraph"] = msg_out["PropagationDirectedGraph"]

        write_log(feedback, name=self.name())
        return output_dict

    def name(self):
        return "simulationresultsprocessing"

    def displayName(self):
        return self.tr("Bundle")

    def group(self):
        return self.tr(self.groupId())

    def groupId(self):
        return "simulatorpostprocessing"

    def tr(self, string):
        return QCoreApplication.translate("Processing", string)

    def createInstance(self):
        return PostSimulationAlgorithm()

    def helpString(self):
        return self.shortHelpString()

    def shortHelpString(self):
        return self.tr(
            """<b>Warning: Enabling Propagation Directed Graph can hang-up your system</b>, around 300.000 arrows is manageable (can be counted in Messages folder, using bash $wc -l Messages*csv)
            To process them anyway, use its Propagation DiGraph algorithm unchecking 'Open output file after running algorithm'
            <i>The alternative visualization is using <b>Propagation Fire Scars</b> for very large simulations</i><br><br>
            """
        )


class MessagesSIMPP(QgsProcessingAlgorithm):
    """Messages Simulation Post Processing Algorithm
    TODO QgsProject.instance().layerTreeRoot().findLayer(layer.id()).setItemVisibilityChecked(False)
    """

    BASE_LAYER = "BaseLayer"
    IN_MSG = "SampleMessagesFile"
    OUTPUT_LAYER = "PropagationDirectedGraph"
    OUT_PICKLED = "PickledMessages"

    def checkParameterValues(self, parameters: dict[str, Any], context: QgsProcessingContext) -> tuple[bool, str]:
        files, msg_dir, msg_name, ext = get_files(Path(self.parameterAsString(parameters, self.IN_MSG, context)))
        if files == []:
            return False, f"{msg_dir} does not contain any non-empty '{msg_name}[0-9]*.{ext}' files"
        return True, ""

    def initAlgorithm(self, config):
        self.addParameter(
            QgsProcessingParameterRasterLayer(
                name=self.BASE_LAYER,
                description=self.tr("Base raster (normally fuel or elevation) to get the geotransform"),
                defaultValue=[QgsProcessing.TypeRaster],
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterFile(
                name=self.IN_MSG,
                description=(
                    "Sample Messages file (normally firesim_yymmdd_HHMMSS/results/Messages/MessagesFile01.csv)\nAll"
                    " ChosenName[0-9]*.csv files will be loaded"
                ),
                behavior=QgsProcessingParameterFile.File,
                extension="csv",
                defaultValue=None,
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterFeatureSink(
                name=self.OUTPUT_LAYER,
                description=self.tr("Output propagation digraph layer"),
                type=QgsProcessing.TypeVectorLine,
                optional=True,
            )
        )
        qparamfd = QgsProcessingParameterFileDestination(
            name=self.OUT_PICKLED,
            description=self.tr(
                "Output pickled messages file (needed by BC or DPV metrics, defaults to"
                " results/Messages/messages.pickle)"
            ),
            fileFilter="pickled files (*.pickled)",
            # defaultValue=defaultValue,
            optional=True,
            createByDefault=False,
        )
        qparamfd.setMetadata({"widget_wrapper": {"dontconfirmoverwrite": True}})
        self.addParameter(qparamfd)

    def processAlgorithm(self, parameters, context, feedback):
        """Here is where the processing itself takes place."""
        # BASE LAYER
        base_raster = self.parameterAsRasterLayer(parameters, self.BASE_LAYER, context)
        _, raster_props = read_raster(base_raster.publicSource(), data=False)
        feedback.pushDebugInfo(f"base_raster.crs(): {base_raster.crs()}")
        GT = raster_props["Transform"]
        W = raster_props["RasterXSize"]
        H = raster_props["RasterYSize"]
        # set output layer
        fields = QgsFields()
        fields.append(QgsField(name="simulation", type=QVariant.Int, len=10))
        fields.append(QgsField(name="time", type=QVariant.Int, len=10))
        # TODO remove (,)
        (sink, dest_id) = self.parameterAsSink(
            parameters,
            self.OUTPUT_LAYER,
            context,
            fields,
            QgsWkbTypes.MultiLineString,  # >v3.3 ? Qgis.WkbType.MultiLineString,
            base_raster.crs(),
        )
        # feedback.pushDebugInfo(f"dest_id: {dest_id}, type: {type(dest_id)}")
        # feedback.pushDebugInfo(f"sink: {sink}, type: {type(sink)}")
        # get messages
        sample_messages_file = Path(self.parameterAsString(parameters, self.IN_MSG, context))
        files, msg_dir, msg_name, ext = get_files(sample_messages_file)
        if files == []:
            feedback.reportError(f"{msg_dir} does not contain any non-empty '{msg_name}[0-9]*{ext}' files")
            raise QgsProcessingException(f"{msg_dir} does not contain any non-empty '{msg_name}[0-9]*{ext}' files")
        feedback.pushDebugInfo(f"{len(files)} messages files, first: {files[0]}...")
        # build digraphs
        data = []
        for count, afile in enumerate(files):
            sim_id = search("\\d+", afile.stem).group(0)
            data += [
                loadtxt(
                    afile, delimiter=",", dtype=[("i", int32), ("j", int32), ("t", int32)], usecols=(0, 1, 2), ndmin=1
                )
            ]
            # 1 based to 0 based
            data[-1]["i"] -= 1
            data[-1]["j"] -= 1
            feedback.pushDebugInfo(f"simulation id: {sim_id}, edges: {len(data)}")
            if sink:
                # build line add to sink
                for i, j, time in data[-1]:
                    i_x_px, i_y_ln = id2xy(i, W, H)
                    i_x_geo, i_y_geo = transform_coords_to_georef(i_x_px + 0.5, i_y_ln + 0.5, GT)
                    # feedback.pushDebugInfo(f"i_x_geo, i_y_geo: {i_x_geo}, {i_y_geo}, time: {time}")
                    j_x_px, j_y_ln = id2xy(j, W, H)
                    j_x_geo, j_y_geo = transform_coords_to_georef(j_x_px + 0.5, j_y_ln + 0.5, GT)
                    # feedback.pushDebugInfo(f"j_x_geo, j_y_geo: {j_x_geo}, {j_y_geo}, time: {time}")
                    # TODO id = int(f"{str(sim_id).zfill(total_sims)}_{i.zfill...}_{j}")
                    feature = QgsFeature(fields)
                    # feature.setId(int(sim_id))
                    feature.setAttributes([int(sim_id), int(time)])
                    feature.setGeometry(QgsLineString([QgsPoint(i_x_geo, i_y_geo), QgsPoint(j_x_geo, j_y_geo)]))
                    sink.addFeature(feature, QgsFeatureSink.FastInsert)
                    # feedback.pushDebugInfo(f"j_x_geo, j_y_geo: {j_x_geo}, {j_y_geo}, time: {time}, sim_idx: {sim_idx}")
                    if feedback.isCanceled():
                        break
            elif feedback.isCanceled():
                break
            feedback.setProgress(int(count * len(files)))

        filename = self.parameterAsFileOutput(parameters, self.OUT_PICKLED, context)
        # feedback.pushCommandInfo(f"filename: {filename}, type: {type(filename)}")
        if filename == "":
            filename = Path(sample_messages_file.parent, "messages.pickle")
        with open(filename, "wb") as f:
            pickle_dump(data, f)

        # handle_post_processing(context, feedback, layer_id=dest_id, style="propagation")
        if context.willLoadLayerOnCompletion(dest_id):
            layer = QgsProcessingUtils.mapLayerFromString(dest_id, context)
            layer_details = context.LayerDetails(
                layer.name(), context.project(), dest_id, QgsProcessingUtils.LayerHint.Vector
            )
            layer_details.groupName = NAME["layer_group"]
            layer_details.layerSortKey = 1
            context.addLayerToLoadOnCompletion(dest_id, layer_details)
            context.layerToLoadOnCompletionDetails(dest_id).setPostProcessor(run_alg_styler_propagation())

        write_log(feedback, name=self.name())
        return {self.OUTPUT_LAYER: dest_id, self.OUT_PICKLED: str(filename)}

    # def postProcessAlgorithm(self, context, feedback):
    #     """Called after processAlgorithm, use it to load the layer and set the symbology"""
    #     feedback.pushDebugInfo(f"postProcessAlgorithm start {context}")
    #     # layer = QgsProcessingUtils.mapLayerFromString(self.dest_id, context)
    #     layer = context.getMapLayer(self.dest_id)
    #     layer.loadNamedStyle(str(Path(assets_dir, "messages.qml")))
    #     # layer.triggerRepaint()
    #     return {self.OUTPUT_LAYER: self.dest_id}

    def tr(self, string):
        return QCoreApplication.translate("Processing", string)

    def createInstance(self):
        return MessagesSIMPP()

    def group(self):
        return self.tr("Simulator Post Processing")

    def groupId(self):
        return "simulatorpostprocessing"

    def name(self):
        return "propagationdigraph"

    def displayName(self):
        return self.tr("Propagation DiGraph")

    def icon(self):
        return QIcon(":/plugins/fireanalyticstoolbox/assets/burntime.svg")

    def helpString(self):
        return self.shortHelpString()

    def shortHelpString(self):
        return self.tr(
            "Warning: Uncheck 'Open output file after running algorithm' if the graph is too big or your computer too slow."
        )


class StatisticSIMPP(QgsProcessingAlgorithm):
    """Statistic Simulation Post Processing Algorithm"""

    IN_STAT = "SampleStatisticFile"
    BASE_LAYER = "BaseLayer"
    DATA_TYPE = "DataType"
    OUTPUT_RASTER = "OutputRaster"
    OUTPUT_RASTER_2 = "OutputRasterStats"
    gdal_dt = [GDT_Float32, GDT_Int16]
    numpy_dt = [float32, int16]
    dt_string = ["float32", "int16"]

    def checkParameterValues(self, parameters: dict[str, Any], context: QgsProcessingContext) -> tuple[bool, str]:
        files, stat_dir, stat_name, ext = get_files(Path(self.parameterAsString(parameters, self.IN_STAT, context)))
        if files == []:
            return False, f"{stat_dir} does not contain any non-empty '{stat_name}[0-9]*{ext}' files"
        return True, ""

    def initAlgorithm(self, config):
        self.addParameter(
            QgsProcessingParameterRasterLayer(
                name=self.BASE_LAYER,
                description=self.tr("Base raster (normally fuel or elevation) to get the geotransform"),
                defaultValue=[QgsProcessing.TypeRaster],
                optional=False,
            )
        )
        known = [item["dir"] + sep + item["file"] for item in STATS]
        self.addParameter(
            QgsProcessingParameterFile(
                name=self.IN_STAT,
                description=(
                    "Sample Spatial Statistic file (normally"
                    " firesim_yymmdd_HHMMSS/results/Statistic/statistic.asc)\nAll ChosenName[0-9]*.asc files will be"
                    " loaded\nKnown: "
                )
                + ", ".join(known),
                behavior=QgsProcessingParameterFile.File,
                extension="asc",
                defaultValue=None,
                optional=False,
            )
        )
        qppe = QgsProcessingParameterEnum(
            name=self.DATA_TYPE,
            description=self.tr(
                "data type\nSpeed-up processing and lower memory requirements by casting to integers\n(Crown is"
                " integer)"
            ),
            options=self.dt_string,
            allowMultiple=False,
            defaultValue="float32",
            optional=False,
            usesStaticStrings=False,
        )
        qppe.setFlags(qppe.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(qppe)
        self.addParameter(
            QgsProcessingParameterRasterDestination(
                name=self.OUTPUT_RASTER,
                description=self.tr("Output raster"),
                # defaultValue=None,
                # optional=False,
                # createByDefault=True,
            )
        )
        self.addParameter(
            QgsProcessingParameterRasterDestination(
                name=self.OUTPUT_RASTER_2,
                description=self.tr("Output raster mean & std"),
                # defaultValue=None,
                optional=True,
                createByDefault=True,
            )
        )

    def processAlgorithm(self, parameters, context, feedback):
        """proc algo"""
        feedback.pushDebugInfo(f"processAlgorithm start, parameters: {parameters}, type: {type(parameters)}")
        # get base map
        base_raster = self.parameterAsRasterLayer(parameters, self.BASE_LAYER, context)
        _, raster_props = read_raster(base_raster.publicSource(), data=False)
        feedback.pushDebugInfo(f"base_raster.crs(): {base_raster.crs()}")
        GT = raster_props["Transform"]
        W = raster_props["RasterXSize"]
        H = raster_props["RasterYSize"]
        # get data
        files, stat_dir, stat_name, ext = get_files(Path(self.parameterAsString(parameters, self.IN_STAT, context)))
        if files == []:
            feedback.reportError(f"{stat_dir} does not contain any non-empty '{stat_name}[0-9]*{ext}' files")
            raise QgsProcessingException(f"{stat_dir} does not contain any non-empty '{stat_name}[0-9]*{ext}' files")
        feedback.pushDebugInfo(f"{len(files)} files, first: {files[0]}...")
        # infer dimensional units
        if unit := [item["unit"] for item in STATS if item["file"] == stat_name]:
            unit = unit[0]
        else:
            unit = None
        # out raster
        output_raster_filename = self.parameterAsOutputLayer(parameters, self.OUTPUT_RASTER, context)
        raster_format = get_output_raster_format(output_raster_filename, feedback)
        feedback.pushDebugInfo(f"output_raster: {output_raster_filename}, {raster_format}")
        # dtype
        data_type_idx = self.parameterAsEnum(parameters, self.DATA_TYPE, context)
        feedback.pushDebugInfo(
            f"data_type_idx: {data_type_idx}, {self.gdal_dt[data_type_idx]}, {self.numpy_dt[data_type_idx]}"
        )
        # create
        dst_ds = gdal.GetDriverByName(raster_format).Create(
            output_raster_filename, W, H, len(files), self.gdal_dt[data_type_idx]
        )
        dst_ds.SetGeoTransform(GT)  # specify coords
        dst_ds.SetProjection(base_raster.crs().authid())  # export coords to file

        # colors = get_color_table(feedback, cm = colormaps.get('magma'))
        data = []
        for count, afile in enumerate(files):
            sim_id = search("\\d+", afile.stem).group(0)
            data += [loadtxt_nodata(afile, dtype=self.numpy_dt[data_type_idx], skiprows=6)]
            feedback.pushDebugInfo(f"simulation id: {sim_id}, data: {data[-1].shape}")
            band = dst_ds.GetRasterBand(count + 1)
            # if 0 != band.SetDescription(f"simulation id: {sim_id}"):
            #     feedback.pushWarning(f"SetDescription failed for {band}")
            # TODO
            # r"""SetUnitType(Band self, char const * val) -> CPLErr"""
            if unit:
                band.SetUnitType(unit)
            # r"""SetStatistics(Band self, double min, double max, double mean, double stddev) -> CPLErr"""
            # NOT THIS : band.SetStatistics(data[-1].min(), data[-1].max(), data[-1].mean(), data[-1].std())
            # r"""SetCategoryNames(Band self, char ** papszCategoryNames) -> CPLErr"""
            # band.SetCategoryNames(["min", "max", "mean", "stddev"])
            # ds.SetMetadata({"X_BAND": "1" }, "GEOLOCATION")
            # band.SetCategoryNames([f"simulation id: {sim_idx}"])
            # colors = get_color_table(feedback, data[-1].min(), data[-1].max(), cm=colormaps.get("magma"))
            # feedback.pushDebugInfo(f"colors: {colors} {colors.GetCount()}, {data[-1].min()}, {data[-1].max()}")
            # if 0 != band.SetRasterColorInterpretation(GCI_PaletteIndex):
            #     feedback.pushWarning(f"SetRasterColorInterpretation failed for {band}")
            # if 0 != band.SetRasterColorTable(colors):
            #     feedback.pushWarning(f"SetRasterColorTable failed for {band}")
            if 0 != band.SetNoDataValue(0):
                feedback.pushWarning(f"Set No Data failed for {afile}")
            if 0 != band.WriteArray(data[-1]):
                feedback.pushWarning(f"WriteArray failed for {afile}")
            if feedback.isCanceled():
                break
            # band.FlushCache()  # write to disk
            # band = None
            # colors = None
            feedback.setProgress(int(count * len(files)))
        data = array(data)
        dst_ds.FlushCache()  # write to disk
        dst_ds = None
        if context.willLoadLayerOnCompletion(output_raster_filename):
            # attach post processor
            display_name = f"{stat_name}_{self.numpy_dt[data_type_idx].__name__}"
            layer_details = context.LayerDetails(
                display_name, context.project(), display_name, QgsProcessingUtils.LayerHint.Raster
            )
            layer_details.groupName = NAME["layer_group"]
            layer_details.layerSortKey = 2
            context.addLayerToLoadOnCompletion(output_raster_filename, layer_details)
            context.layerToLoadOnCompletionDetails(output_raster_filename).setPostProcessor(
                run_alg_styler(
                    display_name,
                    layer_min_val=data.min(),
                    layer_max_val=data.max(),
                    layer_bands=len(files) + 1,
                )
            )
        output_dict = {self.OUTPUT_RASTER: output_raster_filename}

        if len(files) > 1:
            # out raster
            output_raster2_filename = self.parameterAsOutputLayer(parameters, self.OUTPUT_RASTER_2, context)
            raster_format2 = get_output_raster_format(output_raster2_filename, feedback)
            feedback.pushDebugInfo(f"output_raster2: {output_raster2_filename}, {raster_format2}")
            # create
            dst_ds2 = gdal.GetDriverByName(raster_format2).Create(
                output_raster2_filename, W, H, 2, self.gdal_dt[data_type_idx]
            )
            dst_ds2.SetGeoTransform(GT)  # specify coords
            dst_ds2.SetProjection(base_raster.crs().authid())  # export coords to file
            band = dst_ds2.GetRasterBand(1)
            # mean
            band = dst_ds2.GetRasterBand(1)
            if 0 != band.SetNoDataValue(0):
                feedback.pushWarning("Set No Data failed for mean band")
            if 0 != band.WriteArray(data.mean(axis=0)):
                feedback.pushWarning("WriteArray failed for mean band")
            # std
            band = dst_ds2.GetRasterBand(2)
            if 0 != band.SetNoDataValue(0):
                feedback.pushWarning("Set No Data failed for mean band")
            if 0 != band.WriteArray(data.std(axis=0)):
                feedback.pushWarning("WriteArray failed for mean band")
            dst_ds2.FlushCache()  # write to disk
            dst_ds2 = None
            output_dict[self.OUTPUT_RASTER_2] = output_raster2_filename
            # rename if showing
            if context.willLoadLayerOnCompletion(output_raster2_filename):
                layer_details = context.layerToLoadOnCompletionDetails(output_raster2_filename)
                layer_details.name = f"{stat_name}_mean&std_{self.numpy_dt[data_type_idx].__name__}"
                layer_details.groupName = NAME["layer_group"]
                layer_details.layerSortKey = 3
        else:
            output_dict[self.OUTPUT_RASTER_2] = None

        write_log(feedback, name=self.name())
        return output_dict

    # def postProcessAlgorithm(self, context, feedback):
    #     """Called after processAlgorithm, use it to load the layer and set the symbology"""
    #     feedback.pushDebugInfo(f"postProcessAlgorithm start {context}")
    #     # layer = QgsProcessingUtils.mapLayerFromString(self.dest_id, context)
    #     layer = context.getMapLayer(self.dest_id)
    #     layer.loadNamedStyle(str(Path(assets_dir, "messages.qml")))
    #     # layer.triggerRepaint()
    #     return {self.OUTPUT_LAYER: self.dest_id}

    def tr(self, string):
        return QCoreApplication.translate("Processing", string)

    def createInstance(self):
        return StatisticSIMPP()

    def group(self):
        return self.tr("Simulator Post Processing")

    def groupId(self):
        return "simulatorpostprocessing"

    def name(self):
        return "statistic"

    def displayName(self):
        return self.tr("Spatial Statistic")

    def icon(self):
        return QIcon(":/plugins/fireanalyticstoolbox/assets/fireface.svg")


class ScarSIMPP(QgsProcessingAlgorithm):
    """Fire scar Simulation Post Processing Algorithm"""

    IN_SCAR = "SampleScarFile"
    BASE_LAYER = "BaseLayer"
    # IN_FIXGEOM = "FixGeometries"
    OUT_RASTER = "ScarRaster"
    OUT_POLY = "ScarPolygon"
    OUT_BP = "BurnProbability"

    def checkParameterValues(self, parameters: dict[str, Any], context: QgsProcessingContext) -> tuple[bool, str]:
        retval, retmsg, files, scar_dir, scar_name, ext = get_scar_files(
            Path(self.parameterAsString(parameters, self.IN_SCAR, context))
        )
        if not retval:
            return False, retmsg
        if files == []:
            return False, f"{scar_dir} does not contain any non-empty '{scar_name}[0-9]*{ext}' files"
        scar_raster = self.parameterAsOutputLayer(parameters, self.OUT_RASTER, context)
        burn_prob = self.parameterAsOutputLayer(parameters, self.OUT_BP, context)
        scar_poly = self.parameterAsOutputLayer(parameters, self.OUT_POLY, context)
        for afile in [scar_raster, burn_prob]:
            if afile != "":
                ext = Path(afile).suffix[1:]
                if ext not in QgsRasterFileWriter.supportedFormatExtensions(QgsRasterFileWriter.RasterFormatOptions()):
                    return False, f"{self.OUT_RASTER} format .{ext} not supported"
        if scar_poly == "" and scar_raster == "" and burn_prob == "":
            return False, "No output selected!"
        return True, ""

    def initAlgorithm(self, config):
        self.addParameter(
            QgsProcessingParameterRasterLayer(
                name=self.BASE_LAYER,
                description=self.tr("Base raster (normally fuel or elevation) to get the geotransform"),
                defaultValue=[QgsProcessing.TypeRaster],
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterFile(
                name=self.IN_SCAR,
                description=(
                    "Sample Fire Scar file (normally"
                    " firesim_yymmdd_HHMMSS/results/Grids/Grids[0-9]*/ForestGrid[0-9]*.csv)"
                ),
                behavior=QgsProcessingParameterFile.File,
                extension="csv",
                defaultValue=None,
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterRasterDestination(
                name=self.OUT_RASTER,
                description=self.tr("Output final scar raster"),
                optional=True,
                createByDefault=True,
            )
        )
        self.addParameter(
            QgsProcessingParameterFeatureSink(
                name=self.OUT_POLY,
                description=self.tr("Output propagation scars polygons"),
                type=QgsProcessing.TypeVectorPolygon,
                optional=True,
                createByDefault=True,
            )
        )
        # self.addParameter(
        #     QgsProcessingParameterBoolean(
        #         name=self.IN_FIXGEOM,
        #         description=("Fix geometries of the generated propagation polygons"),
        #         defaultValue=False,
        #         optional=True,
        #     )
        # )
        self.addParameter(
            QgsProcessingParameterRasterDestination(
                name=self.OUT_BP,
                description=self.tr("Output burn probability raster"),
                optional=True,
                createByDefault=True,
            )
        )

    def processAlgorithm(self, parameters, context, feedback):
        """Here is where the processing itself takes place."""
        # feedback.pushDebugInfo("processAlgorithm start")
        output_dict = {}
        # get base map
        base_raster = self.parameterAsRasterLayer(parameters, self.BASE_LAYER, context)
        _, raster_props = read_raster(base_raster.publicSource(), data=False)
        feedback.pushDebugInfo(f"base_raster crs auth: {base_raster.crs().authid()}")
        GT = raster_props["Transform"]
        W = raster_props["RasterXSize"]
        H = raster_props["RasterYSize"]
        # get IN_SCAR -> grids, final_grids
        sample_file = Path(self.parameterAsString(parameters, self.IN_SCAR, context))
        ext = sample_file.suffix
        if match := search("(\\d+)$", sample_file.stem):
            num = match.group()
        else:
            feedback.reportError(f"sample_file: {sample_file} does not contain a number at the end")
            return {}
        file_name = sample_file.stem[: -len(num)]
        parent1 = sample_file.absolute().parent
        parent2 = sample_file.absolute().parent.parent
        if match := search("(\\d+)$", parent1.name):
            num = match.group()
        else:
            feedback.reportError(
                f"sample_file parent directory: {sample_file.absolute()} does not contain a number at the end"
            )
            return {}
        parent1name = parent1.name[: -len(num)]
        file_gen = parent2.rglob(parent1name + "[0-9]*" + sep + file_name + "[0-9]*" + ext)
        files = []
        sim_id = []
        per_id = []
        for afile in file_gen:
            if afile.is_file() and afile.stat().st_size > 0:
                # print("afile", afile, afile.parent.name, afile.stem)
                files += [afile.relative_to(parent2)]
                sim_id += [search("(\\d+)$", str(afile.parent.name)).group()]
                per_id += [search("(\\d+)$", str(afile.stem)).group()]
        feedback.pushDebugInfo(
            f"Got files:\nsample files[:3]: {files[:3]}\nparent: {parent2}\nname: {file_name}\next: {ext}\n"
        )
        files = array(files)
        sim_id = array(sim_id, dtype=int32)
        per_id = array(per_id, dtype=int32)
        # unique sorts
        simulations = unique(sim_id)
        # files,sim_id,per_id
        grids = []
        final_grids = []
        for s in simulations:
            sim_files = files[sim_id == s]
            sim_periods = per_id[sim_id == s]
            # final
            final_grids += [[sim_files[sim_periods.argmax()], s, sim_periods.max()]]
            # sort
            sorted_periods = argsort(sim_periods)
            grids += [[sim_files[sorted_periods], s, sim_periods[sorted_periods]]]
        # feedback.pushDebugInfo(f"final_grids: {final_grids}")
        # feedback.pushDebugInfo(f"grids: {grids}")

        # FINAL GRIDS
        data = []
        for i, (afile, _, _) in enumerate(final_grids):
            data += [loadtxt_nodata(Path(parent2, afile), delimiter=",", dtype=int16)]
        data = array(data)
        if not np_any(data[data != 0]):
            feedback.reportError("Nothing burned!")
            return {}

        # store
        with open(Path(parent2, "final_grids.pickle"), "wb") as f:
            pickle_dump(data, f)
        # raster
        output_raster_filename = self.parameterAsOutputLayer(parameters, self.OUT_RASTER, context)
        if output_raster_filename != "":
            raster_format = get_output_raster_format(output_raster_filename, feedback)
            feedback.pushDebugInfo(f"Final grid(s) raster: {output_raster_filename}, {raster_format}")
            dst_ds = gdal.GetDriverByName(raster_format).Create(
                output_raster_filename, W, H, len(final_grids), GDT_Int16
            )
            dst_ds.SetGeoTransform(GT)  # specify coords
            dst_ds.SetProjection(base_raster.crs().authid())  # export coords to file

            feedback.setProgressText(f"Processing final scar(s): {len(final_grids)} files")
            for i, (afile, sim, per) in enumerate(final_grids):
                if feedback.isCanceled():
                    break
                feedback.setProgress(int(i * len(final_grids)))
                feedback.pushDebugInfo(f"sim: {sim}, per: {per}, file: {afile}")
                band = dst_ds.GetRasterBand(i + 1)
                band.SetUnitType("burned")
                if 0 != band.SetNoDataValue(0):
                    feedback.pushWarning(f"Set No Data failed for {afile}")
                if 0 != band.WriteArray(data[i]):
                    feedback.pushWarning(f"WriteArray failed for {afile}")
            dst_ds.FlushCache()  # write to disk
            dst_ds = None
            # if showing
            if context.willLoadLayerOnCompletion(output_raster_filename):
                layer_details = context.layerToLoadOnCompletionDetails(output_raster_filename)
                layer_details.setPostProcessor(run_alg_styler_bin("Final Scars"))
                layer_details.groupName = NAME["layer_group"]
                layer_details.layerSortKey = 2
            feedback.pushDebugInfo("Final scar finished\n")
            output_dict[self.OUT_RASTER] = output_raster_filename

        burn_prob_fname = self.parameterAsOutputLayer(parameters, self.OUT_BP, context)
        if burn_prob_fname != "":
            if data.shape[0] == 1:
                feedback.pushWarning("Only 1 simulation, burn probability doesnt make sense!")
            burn_prob_data = data.mean(axis=0)
            burn_prob_stats = scipy_stats.describe(burn_prob_data[burn_prob_data != 0], axis=None)
            stats_min, stats_max = burn_prob_stats.minmax
            feedback.pushInfo(f"Burn Probability (!=0) stats: {burn_prob_stats}\n")

            burn_prob_format = get_output_raster_format(burn_prob_fname, feedback)
            burn_prob_ds = gdal.GetDriverByName(burn_prob_format).Create(burn_prob_fname, W, H, 1, GDT_Float32)
            burn_prob_ds.SetGeoTransform(GT)  # specify coords
            burn_prob_ds.SetProjection(base_raster.crs().authid())  # export coords to file
            band = burn_prob_ds.GetRasterBand(1)
            band.SetUnitType("probability")
            if 0 != band.SetNoDataValue(0):
                feedback.pushWarning(f"Set No Data failed for {afile}")
            if 0 != band.WriteArray(burn_prob_data):
                feedback.pushWarning(f"WriteArray failed for {afile}")
            burn_prob_ds.FlushCache()  # write to disk
            burn_prob_ds = None
            # if showing
            if context.willLoadLayerOnCompletion(burn_prob_fname):
                layer_name = "Burn Probability"
                layer_details = context.LayerDetails(
                    layer_name,
                    context.project(),
                    layer_name,
                    QgsProcessingUtils.LayerHint.Raster,
                )
                layer_details.groupName = NAME["layer_group"]
                layer_details.layerSortKey = 4
                context.addLayerToLoadOnCompletion(burn_prob_fname, layer_details)
                context.layerToLoadOnCompletionDetails(burn_prob_fname).setPostProcessor(
                    run_alg_styler(
                        layer_name,
                        layer_min_val=stats_min,
                        layer_max_val=stats_max,
                        layer_bands=1,
                    )
                )
            output_dict["BurnProbability"] = burn_prob_fname

        #
        # GRIDS
        #
        # vector
        output_vector_file = self.parameterAsFileOutput(parameters, self.OUT_POLY, context)
        # feedback.pushDebugInfo(f"output_vector_file: {output_vector_file}")
        if output_vector_file != "":
            feedback.pushInfo(f"Propagation polygons {output_vector_file=}")
            # raster for each grid
            src_ds = gdal.GetDriverByName("MEM").Create("", W, H, len(files), gdal.GDT_Float32)
            src_ds.SetGeoTransform(GT)  # specify coords
            src_ds.SetProjection(base_raster.crs().authid())  # export coords to file
            # datasource for shadow geometry vector layer (polygonize output)
            ogr_ds = ogr.GetDriverByName("Memory").CreateDataSource("")
            # srs
            sp_ref = osr.SpatialReference()
            sp_ref.SetFromUserInput(base_raster.crs().authid())
            # otro
            otrods = ogr.GetDriverByName("GPKG").CreateDataSource(output_vector_file)
            otrolyr = otrods.CreateLayer("", srs=sp_ref, geom_type=ogr.wkbPolygon)
            otrolyr.CreateField(ogr.FieldDefn("simulation", ogr.OFTInteger))
            otrolyr.CreateField(ogr.FieldDefn("time", ogr.OFTInteger))
            otrolyr.CreateField(ogr.FieldDefn("area", ogr.OFTInteger))
            otrolyr.CreateField(ogr.FieldDefn("perimeter", ogr.OFTInteger))

            msg = f"Processing propagation scar polygons, {len(grids)} simulations"
            feedback.setProgressText(msg)
            data = []
            count = 0
            for i, (files, sim, pers) in enumerate(grids):
                feedback.pushDebugInfo(f"simulation id: {sim}, total periods: {len(pers)}")
                for j, (afile, per) in enumerate(zip(files[::-1], pers[::-1])):
                    feedback.setProgress(int(count * len(files)))
                    if feedback.isCanceled():
                        break
                    data += [loadtxt(Path(parent2, afile), delimiter=",", dtype=int16)]
                    if not np_any(data[-1] == 1):
                        feedback.pushWarning(f"no fire in {afile}")
                        continue
                    count += 1
                    layer_name = f"propagation_sim{sim}_per{per}"
                    # feedback.pushDebugInfo(f"{layer_name}, file: {afile}")
                    feedback.pushDebugInfo(f"{sim=}, {per=}, {afile=}, {count=}")

                    # raster polygonize
                    src_band = src_ds.GetRasterBand(count)
                    src_band.SetNoDataValue(0)
                    src_band.WriteArray(data[-1])
                    ogr_layer = ogr_ds.CreateLayer("", srs=sp_ref)
                    gdal.Polygonize(src_band, src_band, ogr_layer, -1, ["8CONNECTED=8"])
                    # assumes only one feature : 8 neighbors provides that
                    feat = ogr_layer.GetNextFeature()
                    geom = feat.GetGeometryRef()

                    # create the feature and set values
                    featureDefn = otrolyr.GetLayerDefn()
                    feature = ogr.Feature(featureDefn)
                    feature.SetGeometry(geom)
                    feature.SetField("simulation", int(sim))
                    feature.SetField("time", int(per))
                    feature.SetField("area", int(geom.GetArea()))
                    feature.SetField("perimeter", int(geom.Boundary().Length()))
                    otrolyr.CreateFeature(feature)

            feedback.pushDebugInfo("not fixing geometries...")

            # if scar_fixed_geom := processing.run(
            #     "native:fixgeometries",
            #     {
            #         "INPUT": output_vector_file,  # "memory:ds" otrolyr "memory:tmp"
            #         "METHOD": 1,
            #         "OUTPUT": output_vector_file,  # QgsProcessing.TEMPORARY_OUTPUT
            #     },
            #     context=context,
            #     feedback=feedback,
            #     is_child_algorithm=True,
            # ):
            #     if scar_fixed_geom := scar_fixed_geom.get("OUTPUT"):
            #         layer_details = context.LayerDetails(
            #             "Propagation Scars",
            #             context.project(),
            #             "Propagation Scars",
            #             QgsProcessingUtils.LayerHint.Vector,
            #         )
            #         layer_details.forceName = True
            #         layer_details.groupName = NAME["layer_group"]
            #         layer_details.layerSortKey = 2
            #         context.addLayerToLoadOnCompletion(scar_fixed_geom, layer_details)
            #         output_dict[self.OUT_POLY] = scar_fixed_geom

            otrolyr.SyncToDisk()
            otrolyr = None

            otrods.FlushCache()  # write to disk
            otrods = None

            src_ds.FlushCache()  # write to disk
            src_ds = None

            # store grids
            data = array(data)
            with open(Path(parent2, "grids.pickle"), "wb") as f:
                pickle_dump(data, f)

        write_log(feedback, name=self.name())
        return output_dict

    def name(self):
        return "scar"

    def displayName(self):
        return self.tr("Fire Scar")

    def group(self):
        return self.tr("Simulator Post Processing")

    def groupId(self):
        return "simulatorpostprocessing"

    def tr(self, string):
        return QCoreApplication.translate("Processing", string)

    def createInstance(self):
        return ScarSIMPP()

    def icon(self):
        return QIcon(":/plugins/fireanalyticstoolbox/assets/bodyscar.svg")

    def helpString(self):
        return self.shortHelpString()

    def shortHelpString(self):
        return self.tr(
            """ - Output final scar raster needs simulation ran with Final Fire Scar option, each band is a simulation
            - Output burn probability raster is the mean of all simulations, requires >1 simulations
            - Propagation Scars Polygons is processed in memory in gpkg format, then converted by qgis's native:fixgeometries algorithm (also needs the simulation ran with Propagation Fire Scars option)"""
        )


def run_alg_styler_propagation():
    """Create a New Post Processor class and returns it"""

    class LayerPostProcessor(QgsProcessingLayerPostProcessorInterface):
        instance = None

        def postProcessLayer(self, layer, context, feedback):
            if layer.isValid():
                # QgsProject.instance().layerTreeRoot().findLayer(layer.id()).setItemVisibilityChecked(False)
                processing.run(
                    "qgis:setstyleforvectorlayer",
                    {"INPUT": layer, "STYLE": str(Path(assets_dir, "messages.qml"))},
                    context=context,
                    feedback=feedback,
                    is_child_algorithm=True,
                )
                renderer = layer.renderer()
                # FIXME DeprecationWarning
                renderer.updateClasses(layer, QgsGraduatedSymbolRenderer.Mode.Jenks, 10)
                # enum : EqualInterval , Quantile , Jenks , StdDev , Pretty , Custom
                # layer.triggerRepaint()
                layer.setSubsetString('"time"<=120  AND "simulation" = 1')
                QgsMessageLog.logMessage(f"propagation styling done! {layer.name()}", TAG, Qgis.Info)
            else:
                QgsMessageLog.logMessage(
                    f"propagation styling failed! layer not valid: {layer.name()}", TAG, Qgis.Critical
                )

        # Hack to work around sip bug!
        @staticmethod
        def create() -> "LayerPostProcessor":
            LayerPostProcessor.instance = LayerPostProcessor()
            return LayerPostProcessor.instance

    return LayerPostProcessor.create()


def run_alg_styler_bin(display_name, layer_bands=1):
    """Create a New Post Processor class and returns it"""

    class LayerPostProcessor(QgsProcessingLayerPostProcessorInterface):
        instance = None
        name = display_name
        bands = layer_bands

        lst = [
            QgsColorRampShader.ColorRampItem(0, QColor(2, 2, 2)),
            QgsColorRampShader.ColorRampItem(1, QColor(222, 222, 222)),
        ]
        class_data = QgsPalettedRasterRenderer.colorTableToClassData(lst)  # <-

        def postProcessLayer(self, layer, context, feedback):
            feedback.pushInfo(f"Inside postProcessLayer: {self.name}")
            if layer.isValid():
                prov = layer.dataProvider()
                layer.setName(self.name)
                feedback.pushInfo(f"Layer valid, set name: {self.name}")
                for band in range(1, self.bands + 1):
                    renderer = QgsPalettedRasterRenderer(prov, band, self.class_data)
                    layer.setRenderer(renderer)
            else:
                feedback.pushInfo(f"Layer not valid: {self.name}")

        # Hack to work around sip bug!
        @staticmethod
        def create() -> "LayerPostProcessor":
            LayerPostProcessor.instance = LayerPostProcessor()
            return LayerPostProcessor.instance

    return LayerPostProcessor.create()


def run_alg_styler(
    display_name,
    layer_color1=(68, 1, 84),
    layer_color2=(253, 231, 37),
    layer_min_val=None,
    layer_max_val=None,
    layer_bands=None,
):
    """Create a New Post Processor class and returns it

    # Just simply creating a new instance of the class was not working
    # for details see https://gis.stackexchange.com/questions/423650/qgsprocessinglayerpostprocessorinterface-only-processing-the-last-layer
    """

    class LayerPostProcessor(QgsProcessingLayerPostProcessorInterface):
        instance = None
        name = display_name
        color1 = layer_color1
        color2 = layer_color2
        min_val = layer_min_val
        max_val = layer_max_val
        bands = layer_bands

        def postProcessLayer(self, layer, context, feedback):
            feedback.pushInfo(f"Inside postProcessLayer: {self.name}")
            if layer.isValid():
                prov = layer.dataProvider()
                if self.min_val is None or self.max_val is None:
                    stats = prov.bandStatistics(1, QgsRasterBandStats.All, layer.extent(), 0)
                    self.min_val = stats.minimumValue if self.min_val is None else self.min_val
                    self.max_val = stats.maximumValue if self.max_val is None else self.max_val
                if self.bands is None:
                    self.bands = layer.bandCount()
                feedback.pushInfo(f"Layer valid: {self.name}")
                layer.setName(self.name)
                for band in range(1, self.bands + 1)[::-1]:
                    fcn = QgsColorRampShader()
                    fcn.setColorRampType(QgsColorRampShader.Interpolated)
                    lst = [
                        QgsColorRampShader.ColorRampItem(self.min_val, QColor(*self.color1)),
                        QgsColorRampShader.ColorRampItem(self.max_val, QColor(*self.color2)),
                    ]
                    fcn.setColorRampItemList(lst)
                    shader = QgsRasterShader()
                    shader.setRasterShaderFunction(fcn)
                    # windows error argument 1 has unexpected type 'QgsMeshDataProvider'
                    renderer = QgsSingleBandPseudoColorRenderer(prov, band, shader)
                    layer.setRenderer(renderer)
                # renderer = QgsSingleBandPseudoColorRenderer(layer.dataProvider(), 1, shader)
                # layer.setRenderer(renderer)
            else:
                feedback.pushInfo(f"Layer not valid: {self.name}")

        # Hack to work around sip bug!
        @staticmethod
        def create() -> "LayerPostProcessor":
            LayerPostProcessor.instance = LayerPostProcessor()
            return LayerPostProcessor.instance

    return LayerPostProcessor.create()


class Renamer(QgsProcessingLayerPostProcessorInterface):
    def __init__(self, layer_name):
        super().__init__()
        self.name = layer_name

    def postProcessLayer(self, layer, context, feedback):
        if layer.isValid():
            layer.setName(self.name)


def get_files(sample_file: Path) -> tuple[list[Path], Path, str, str]:
    """Get a list of files with the same name (+ any digit) and extension and the directory and name of the sample file"""
    ext = sample_file.suffix
    if match := search("(\\d+)$", sample_file.stem):
        num = match.group()
    else:
        raise ValueError(f"sample_file: {sample_file} does not contain a number at the end")
    aname = sample_file.stem[: -len(num)]
    adir = sample_file.absolute().parent
    files = []
    for afile in sorted(adir.glob(aname + "[0-9]*" + ext)):
        if afile.is_file() and afile.stat().st_size > 0:
            files += [afile]
    # QgsMessageLog.logMessage(f"files: {files}, adir: {adir}, aname: {aname}, ext: {ext}", "fire2a", Qgis.Info)
    return files, adir, aname, ext


def get_scar_files(sample_file: Path) -> Tuple[list[Path], Path, str, str]:
    """Get a list of files with the same name (+ any digit) and extension and the directory and name of the sample file
    sample_file = Path('/home/fdo/source/C2F-W/data/Vilopriu_2013/firesim_231001_145657/results/Grids/Grids1/ForestGrid00.csv')
    """
    retval = 0
    ext = sample_file.suffix
    if match := search("(\\d+)$", sample_file.stem):
        num = match.group()
    else:
        return False, f"sample_file: {sample_file} does not contain a number at the end", [], None, None, None
    file_name = sample_file.stem[: -len(num)]
    parent1 = sample_file.absolute().parent
    parent2 = sample_file.absolute().parent.parent
    if match := search("(\\d+)$", parent1.name):
        num = match.group()
    else:
        return False, f"sample_file parent: {sample_file} does not contain a number at the end", [], None, None, None
    parent1name = parent1.name[: -len(num)]
    file_gen = parent2.rglob(parent1name + "[0-9]*" + sep + file_name + "[0-9]*" + ext)
    files = []
    for afile in sorted(file_gen):
        if afile.is_file() and afile.stat().st_size > 0:
            files += [afile.relative_to(parent2)]
    # QgsMessageLog.logMessage(f"files: {files}, adir: {adir}, aname: {aname}, ext: {ext}", "fire2a", Qgis.Info)

    return True, "", files, parent2, file_name, ext


class BetweennessCentralityMetric(QgsProcessingAlgorithm):
    """Messages Simulation Post Processing Algorithm"""

    BASE_LAYER = "BaseLayer"
    IN = "PickledMessages"
    IN_def_k = "UseDefaultInputSamples"
    IN_k = "InputSamples"
    IN_seed = "InputSamplesRNGSeed"
    OUT_R = "BetweennessCentralityRaster"

    def initAlgorithm(self, config):
        self.addParameter(
            QgsProcessingParameterRasterLayer(
                name=self.BASE_LAYER,
                description=self.tr("Base raster (normally fuel or elevation) to get the geotransform"),
                defaultValue=[QgsProcessing.TypeRaster],
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterFile(
                name=self.IN,
                description=(
                    "Pickled messages (normally generated by the Propagation Digraph Algorithm"
                    " results/Messages/messages.pickle)"
                ),
                behavior=QgsProcessingParameterFile.File,
                extension="pickle",
                defaultValue=None,
                optional=False,
            )
        )
        qppb = QgsProcessingParameterBoolean(
            name=self.IN_def_k,
            description=self.tr("Use default sampling ratio K = sqrt(number_of_nodes)/5"),
            defaultValue=True,
            optional=False,
        )
        qppb.setFlags(qppb.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(qppb)
        qppn = QgsProcessingParameterNumber(
            name=self.IN_k,
            description=self.tr(
                "K samples to estimate betweenness."
                "\n Not set and disabled default sampling checkbox means all nodes are used: very slow!"
                "\n Trade-off between accuracy and running time."
            ),
            type=QgsProcessingParameterNumber.Integer,
            # defaultValue = 0, # <- no se puede quitar
            optional=True,
            minValue=1,
            # maxValue=13,
        )
        qppn.setFlags(qppn.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(qppn)
        qppn2 = QgsProcessingParameterNumber(
            name=self.IN_seed,
            description=self.tr("Random number generator seed for sampling. Used if K is not set."),
            type=QgsProcessingParameterNumber.Integer,
            defaultValue=42,
            optional=False,
            # minValue=1,
            # maxValue=13,
        )
        qppn2.setFlags(qppn2.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(qppn2)
        # self.addParameter(
        #     QgsProcessingParameterFeatureSink(
        #         name=self.OUT_L,
        #         description=self.tr("Output BC layer"),
        #         type=QgsProcessing.TypeVectorLine,
        #         optional=True,
        #         createByDefault=True,
        #     )
        # )
        self.addParameter(
            QgsProcessingParameterRasterDestination(
                name=self.OUT_R,
                description=self.tr("Output BC raster"),
                # defaultValue=None,
                # optional=False,
                # createByDefault=True,
            )
        )

    def processAlgorithm(self, parameters, context, feedback):
        """Here is where the processing itself takes place."""
        # BASE LAYER
        base_raster = self.parameterAsRasterLayer(parameters, self.BASE_LAYER, context)
        _, raster_props = read_raster(base_raster.publicSource(), data=False)
        feedback.pushDebugInfo(f"base_raster.crs(): {base_raster.crs()}")
        GT = raster_props["Transform"]
        W = raster_props["RasterXSize"]
        H = raster_props["RasterYSize"]

        data_file = Path(self.parameterAsString(parameters, self.IN, context))
        with open(data_file, "rb") as f:
            data_list = pickle_load(f)
        feedback.pushDebugInfo(f"data_file: {data_file}, len(data_list): {len(data_list)}")

        mdg = MultiDiGraph()
        func = vectorize(lambda x: {"weight": x})
        for k, data in enumerate(data_list):
            # ebunch_to_add : container of 4-tuples (u, v, k, d) for an edge with data and key k
            bunch = vstack((data["i"], data["j"], [k] * len(data), func(data["t"]))).T
            mdg.add_edges_from(bunch)
            if feedback.isCanceled():
                break

        if self.parameterAsBool(parameters, self.IN_def_k, context):
            ksample = int(sqrt(mdg.number_of_nodes() * 5))
        elif self.parameterAsBool(parameters, self.IN_k, context):
            ksample = self.parameterAsInt(parameters, self.IN_k, context)
        else:
            ksample = mdg.number_of_nodes()
        seed = self.parameterAsInt(parameters, self.IN_seed, context)
        feedback.pushDebugInfo(f"ksample: {ksample}, out of {mdg.number_of_nodes()} nodes, seed: {seed}")
        centrality = betweenness_centrality(mdg, k=ksample, weight="weight", seed=seed)

        centrality_array = zeros((H, W), dtype=float32)
        centrality_values = []
        for cell, value in centrality.items():
            i, j = id2xy(cell, W, H)
            centrality_array[j, i] = value
            centrality_values += [value]

        # raster
        output_raster_filename = self.parameterAsOutputLayer(parameters, self.OUT_R, context)
        raster_format = get_output_raster_format(output_raster_filename, feedback)
        feedback.pushDebugInfo(f"output_raster: {output_raster_filename}, {raster_format}")

        dst_ds = gdal.GetDriverByName(raster_format).Create(output_raster_filename, W, H, 1, GDT_Float32)
        dst_ds.SetGeoTransform(GT)  # specify coords
        dst_ds.SetProjection(base_raster.crs().authid())  # export coords to file
        band = dst_ds.GetRasterBand(1)
        band.SetUnitType("centrality")
        if 0 != band.SetNoDataValue(0):
            feedback.pushWarning(f"Set No Data failed for {self.OUT_R}")
        if 0 != band.WriteArray(centrality_array):
            feedback.pushWarning(f"WriteArray failed for {self.OUT_R}")

        centrality_stats = scipy_stats.describe(centrality_values, axis=None)
        stats_min, stats_max = centrality_stats.minmax
        feedback.pushInfo(f"centrality values stats: {centrality_stats}")

        if context.willLoadLayerOnCompletion(output_raster_filename):
            # attach post processor
            display_name = f"{self.OUT_R}"
            layer_details = context.LayerDetails(
                display_name, context.project(), display_name, QgsProcessingUtils.LayerHint.Raster
            )
            layer_details.groupName = NAME["layer_group"]
            layer_details.layerSortKey = 3
            context.addLayerToLoadOnCompletion(output_raster_filename, layer_details)
            context.layerToLoadOnCompletionDetails(output_raster_filename).setPostProcessor(
                run_alg_styler(
                    display_name,
                    layer_min_val=stats_min,
                    layer_max_val=stats_max,
                    layer_bands=1,
                )
            )
        write_log(feedback, name=self.name())
        return {self.OUT_R: output_raster_filename}

    def tr(self, string):
        return QCoreApplication.translate("Processing", string)

    def createInstance(self):
        return BetweennessCentralityMetric()

    def group(self):
        return self.tr(NAME["simm"])

    def groupId(self):
        return jolo(NAME["simm"])

    def name(self):
        return jolo(NAME["bc"])

    def displayName(self):
        return self.tr(NAME["bc"])

    def icon(self):
        return QIcon(":/plugins/fireanalyticstoolbox/assets/bc.svg")


def recursion(G: DiGraph, i: int32, mdpv: ndarray, i2n: list[int]) -> ndarray:
    for j in G.successors(i):
        mdpv[i2n.index(i)] += recursion(G, j, mdpv, i2n)
    return mdpv[i2n.index(i)]


def worker(data, pv, sid):
    # digraph_from_messages(msgfile) -> msgG, root
    msgG = DiGraph()
    msgG.add_weighted_edges_from(data)
    root = data[0][0]
    # shortest_propagation_tree(G, root) -> treeG
    shortest_paths = single_source_dijkstra_path(msgG, root, weight="time")
    del shortest_paths[root]
    treeG = DiGraph()
    for node, shopat in shortest_paths.items():
        for i, node in enumerate(shopat[:-1]):
            treeG.add_edge(node, shopat[i + 1])
    # dpv_maskG(G, root, pv, i2n) -> mdpv
    i2n = [n for n in treeG]
    mdpv = pv[i2n]
    recursion(treeG, root, mdpv, i2n)
    # dpv[i2n] += mdpv
    return mdpv, i2n, sid


def shout_progress(result, feedback):
    _, i2n, sid = result
    feedback.pushDebugInfo(f"Processed simulation {sid}, modified cells {len(i2n)}")


class DownStreamProtectionValueMetric(QgsProcessingAlgorithm):
    """Messages Simulation Post Processing Algorithm"""

    BASE_LAYER = "ProtectionValueRaster"
    IN = "PickledMessages"
    OUT_R = "RasterOutput"
    THREADS = "Threads"

    def initAlgorithm(self, config):
        self.addParameter(
            QgsProcessingParameterRasterLayer(
                name=self.BASE_LAYER,
                description=self.tr("Protection Value Raster (get values & geotransform)"),
                defaultValue=[QgsProcessing.TypeRaster],
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterFile(
                name=self.IN,
                description=(
                    "Pickled messages (normally generated by the Propagation Digraph Algorithm"
                    " results/Messages/messages.pickle)"
                ),
                behavior=QgsProcessingParameterFile.File,
                extension="pickle",
                defaultValue=None,
                optional=False,
            )
        )
        self.addParameter(
            QgsProcessingParameterRasterDestination(
                name=self.OUT_R,
                description=self.tr("Output raster"),
                # defaultValue=None,
                optional=False,
                createByDefault=True,
            )
        )
        # advanced
        qppn = QgsProcessingParameterNumber(
            name=self.THREADS,
            description=self.tr("Maximum number of threads to use simultaneously"),
            type=QgsProcessingParameterNumber.Integer,
            defaultValue=cpu_count() - 1,
            optional=True,
            minValue=1,
            maxValue=cpu_count(),
        )
        qppn.setFlags(qppn.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(qppn)

    def processAlgorithm(self, parameters, context, feedback):
        """Here is where the processing itself takes place."""
        # BASE LAYER
        base_raster = self.parameterAsRasterLayer(parameters, self.BASE_LAYER, context)
        pv, raster_props = read_raster(base_raster.publicSource(), data=True)
        feedback.pushDebugInfo(f"base_raster.crs().authid(): {base_raster.crs().authid()}")
        GT = raster_props["Transform"]
        W = raster_props["RasterXSize"]
        H = raster_props["RasterYSize"]

        data_file = Path(self.parameterAsString(parameters, self.IN, context))
        with open(data_file, "rb") as f:
            data_list = pickle_load(f)
        feedback.pushDebugInfo(f"data_file: {data_file}, len(data_list): {len(data_list)}")
        nsim = len(data_list)

        pv = pv.ravel()
        dpv = zeros(pv.shape, dtype=pv.dtype)

        if platform_system() == "Windows":
            feedback.pushWarning("MsWindows detected! Using the serial DPV calculation, switch to Linux to parallelize")
            for count, data in enumerate(data_list):
                # digraph_from_messages(msgfile) -> msgG, root
                msgG = DiGraph()
                msgG.add_weighted_edges_from(data)
                root = data[0][0]  # checkar que el primer valor del message sea el punto de ignición
                # shortest_propagation_tree(G, root) -> treeG
                shortest_paths = single_source_dijkstra_path(msgG, root, weight="time")
                del shortest_paths[root]
                treeG = DiGraph()
                for node, shopat in shortest_paths.items():
                    for i, node in enumerate(shopat[:-1]):
                        treeG.add_edge(node, shopat[i + 1])
                # dpv_maskG(G, root, pv, i2n) -> mdpv
                i2n = [n for n in treeG]  # TODO change to generator?
                mdpv = pv[i2n]
                recursion(treeG, root, mdpv, i2n)
                dpv[i2n] += mdpv
                feedback.setProgress((count + 1) / nsim * 100)
                if feedback.isCanceled():
                    break
        else:
            # multiprocessing
            threads = self.parameterAsEnum(parameters, self.THREADS, context)
            feedback.pushDebugInfo(f"Orchestrating {nsim} processes in a {threads}-lane parallel execution pool")
            pool = Pool(threads)
            results = [
                pool.apply_async(worker, args=(data, pv, i), callback=partial(shout_progress, feedback=feedback))
                for i, data in enumerate(data_list)
            ]
            while True:
                # user canceled?
                if feedback.isCanceled():
                    feedback.pushWarning("Canceling...")
                    pool.terminate()
                    return {}
                # all done?
                statuses = [result.ready() for result in results]
                if all(statuses):
                    break
                feedback.setProgress(int(100 * sum(statuses) / nsim))
                # wait
                results[statuses.index(False)].wait(1)
            # retrieve
            for result in results:
                sdpv, si2n, sid = result.get()
                dpv[si2n] += sdpv
                # feedback.pushDebugInfo(f"accumulated dpv sum -per simulation {sid}: {dpv.sum()}")
            pool.close()
            pool.join()
        # scale
        dpv = dpv / nsim
        # descriptive statistics
        if np_any(dpv[dpv != 0]):
            dpv_stats = scipy_stats.describe(dpv[dpv != 0.0], axis=None)
            msg = "(!=0)"
        else:
            dpv_stats = scipy_stats.describe(dpv, axis=None)
            feedback.pushWarning("Calculated Downstream Protection Value is zero all around!")
            msg = ""
        stats_min, stats_max = dpv_stats.minmax
        feedback.pushInfo(f"stats {msg}: {dpv_stats}")
        # raster
        output_raster_filename = self.parameterAsOutputLayer(parameters, self.OUT_R, context)
        raster_format = get_output_raster_format(output_raster_filename, feedback)
        feedback.pushDebugInfo(f"output_raster: {output_raster_filename}, {raster_format}")

        dst_ds = gdal.GetDriverByName(raster_format).Create(output_raster_filename, W, H, 1, GDT_Float32)
        dst_ds.SetGeoTransform(GT)  # specify coords
        dst_ds.SetProjection(base_raster.crs().authid())  # export coords to file
        band = dst_ds.GetRasterBand(1)
        band.SetUnitType("protection_value")
        if 0 != band.SetNoDataValue(0):
            feedback.pushWarning(f"Set No Data failed for {self.OUT_R}")
        if 0 != band.WriteArray(float32(dpv.reshape(H, W))):
            feedback.pushWarning(f"WriteArray failed for {self.OUT_R}")

        if context.willLoadLayerOnCompletion(output_raster_filename):
            # attach post processor
            display_name = NAME["dpv"]
            layer_details = context.LayerDetails(
                display_name, context.project(), display_name, QgsProcessingUtils.LayerHint.Raster
            )
            layer_details.groupName = NAME["layer_group"]
            layer_details.layerSortKey = 3
            context.addLayerToLoadOnCompletion(output_raster_filename, layer_details)
            context.layerToLoadOnCompletionDetails(output_raster_filename).setPostProcessor(
                run_alg_styler(
                    display_name,
                    layer_min_val=stats_min,
                    layer_max_val=stats_max,
                    layer_bands=1,
                )
            )

        write_log(feedback, name=self.name())
        return {self.OUT_R: output_raster_filename}

    def tr(self, string):
        return QCoreApplication.translate("Processing", string)

    def createInstance(self):
        return DownStreamProtectionValueMetric()

    def group(self):
        return self.tr(NAME["simm"])

    def groupId(self):
        return jolo(NAME["simm"])

    def name(self):
        return jolo(NAME["dpv"])

    def displayName(self):
        return self.tr(NAME["dpv"])

    def icon(self):
        return QIcon(":/plugins/fireanalyticstoolbox/assets/dpv.svg")


def handle_post_processing(
    context, feedback, layer=None, layer_id=None, display_name="", style=None, group_name=NAME["layer_group"], **kwargs
) -> None:
    if not layer:
        layer = QgsProcessingUtils.mapLayerFromString(layer_id, context)
    if not layer_id:
        layer_id = layer.id()
    if display_name == "":
        display_name = layer.name()
    layer_details = context.LayerDetails(display_name, context.project(), display_name)
    context.addLayerToLoadOnCompletion(
        display_name,
        layer_details,
    )
    if context.willLoadLayerOnCompletion(layer_id):
        if style == "pseudocolor":
            context.layerToLoadOnCompletionDetails(layer_id).setPostProcessor(
                run_alg_styler(display_name, (0, 0, 255), (255, 0, 0), **kwargs)
            )
        elif style == "bin":
            context.layerToLoadOnCompletionDetails(layer_id).setPostProcessor(
                run_alg_styler_bin(display_name, (0, 0, 255), (255, 0, 0), **kwargs)
            )
        elif style == "propagation":
            context.layerToLoadOnCompletionDetails(layer_id).setPostProcessor(run_alg_styler_propagation())
